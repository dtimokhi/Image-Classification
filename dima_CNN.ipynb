{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras as ks\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_data(root):\n",
    "    images = []\n",
    "    for subdir, dirs, files in os.walk(root):\n",
    "        for file in files:\n",
    "            read_file = subdir + \"/\" + file\n",
    "            img = cv.imread(read_file,cv.IMREAD_GRAYSCALE)\n",
    "            images.append(img)\n",
    "    return np.array(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprossesing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will generate the image data and normalize the data to be between 0 and 1.\n",
    "Darker pixels will be closer to 0 and lighter pixels will be closer to 0. Furthermore, we are using grey-scale ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "frown = create_image_data(\"data/60frowns/\")/255\n",
    "smile = create_image_data(\"data/60smiles/\")/255\n",
    "\n",
    "frowns = frown.reshape(frown.shape[0],60,60,1).astype('float32')\n",
    "smiles = smile.reshape(smile.shape[0],60,60,1).astype('float32')\n",
    "\n",
    "X = np.concatenate([frowns, smiles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "frowns_y = np.repeat(0, frown.shape[0])\n",
    "smiles_y = np.repeat(1, smile.shape[0])\n",
    "\n",
    "y = np.concatenate([frowns_y,smiles_y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splits the data intro training and testing sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the ImageDataGenerator we will create additional images for the model to trail on since we only have 360 images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gen = ImageDataGenerator()\n",
    "img_gen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Model\n",
    "This will train and build the CNN model. \n",
    "\n",
    "### Layers\n",
    "    1. Convolutional layer: \n",
    "        - Input shape: (60, 60, 1)\n",
    "        - RelU activation function a' = max(0, a) for each pixel\n",
    "        - L2 regularization with a = 0.001, multiply each weight in training by 0.001\n",
    "    2. Pooling layer:\n",
    "        - Pooling size = (3,3)\n",
    "    3. Dense layer (Fully Connected layer):\n",
    "        - Output size of 1\n",
    "        - Sigmoid activation function\n",
    "### Compiling the model\n",
    "    - We will use a binary_crossentropy loss function\n",
    "    - RMsprop optimizer function\n",
    "### Fitting the model\n",
    "#### ImageDataGenerator\n",
    "    - A key detail about our model is that we will be generating 30 new images each epoch during the training of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras import regularizers\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "45/45 [==============================] - 4s 94ms/step - loss: 0.4123 - acc: 0.8554\n",
      "Epoch 2/5\n",
      "45/45 [==============================] - 2s 34ms/step - loss: 0.1336 - acc: 0.9737\n",
      "Epoch 3/5\n",
      "45/45 [==============================] - 2s 34ms/step - loss: 0.0502 - acc: 0.9900\n",
      "Epoch 4/5\n",
      "45/45 [==============================] - 2s 34ms/step - loss: 0.0222 - acc: 0.9985\n",
      "Epoch 5/5\n",
      "45/45 [==============================] - 2s 34ms/step - loss: 0.0110 - acc: 1.0000\n",
      "108/108 [==============================] - 1s 12ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07220148446935194, 0.9814814792739021]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ks.Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=15,kernel_size=(5,5),activation='relu', input_shape=(60,60,1), kernel_regularizer=regularizers.l2(0.001)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='RMSprop', metrics = ['accuracy'])\n",
    "history_model = model.fit_generator(img_gen.flow(X_train,y_train, batch_size=30),steps_per_epoch=45, epochs=5);\n",
    "history_evaluate = model.evaluate(X_test, y_test);\n",
    "history_evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_88 (Conv2D)           (None, 56, 56, 15)        390       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_83 (MaxPooling (None, 28, 28, 15)        0         \n",
      "_________________________________________________________________\n",
      "flatten_83 (Flatten)         (None, 11760)             0         \n",
      "_________________________________________________________________\n",
      "dropout_58 (Dropout)         (None, 11760)             0         \n",
      "_________________________________________________________________\n",
      "dense_83 (Dense)             (None, 1)                 11761     \n",
      "=================================================================\n",
      "Total params: 12,151\n",
      "Trainable params: 12,151\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
